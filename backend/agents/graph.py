"""LangGraph í†µí•© ì›Œí¬í”Œë¡œìš° - Supervisor Pattern"""
from typing import Literal, Optional, Dict, List
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage
from dotenv import load_dotenv
import os

from agents.state import TravelPlannerState

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ env íŒŒì¼)
env_path = os.path.join(os.path.dirname(__file__), '..', '..', 'env')
load_dotenv(env_path)


# LLMì„ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì´ˆê¸°í™”í•˜ë„ë¡ ë³€ê²½ (lazy initialization)
def get_llm():
    """LLM ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤ (lazy initialization)"""
    return ChatOpenAI(model="gpt-4o-mini", temperature=0)


# ============================================================================
# Phase 1: í•„ìˆ˜ ì •ë³´ ìˆ˜ì§‘
# ============================================================================

def check_missing_required_info(required_info: Dict) -> Optional[str]:
    """í•„ìˆ˜ ì •ë³´ ì¤‘ ëˆ„ë½ëœ ê²ƒ í™•ì¸"""
    required_fields = {
        "destination": "ëª©ì ì§€",
        "departure": "ì¶œë°œì§€",
        "departure_time": "ì¶œë°œ ì‹œê°„",
        "dates": "ì—¬í–‰ ë‚ ì§œ/ê¸°ê°„",
        "budget": "ì˜ˆì‚°"
    }
    
    for field, korean_name in required_fields.items():
        if not required_info.get(field):
            return korean_name
    return None


def extract_required_info(user_input: str, current_info: Dict) -> Dict:
    """ì‚¬ìš©ì ì…ë ¥ì—ì„œ í•„ìˆ˜ ì •ë³´ ì¶”ì¶œ"""
    llm = get_llm()
    
    prompt = f"""
    ì‚¬ìš©ì ì…ë ¥: "{user_input}"
    í˜„ì¬ ìˆ˜ì§‘ëœ ì •ë³´: {current_info}
    
    ë‹¤ìŒ ì •ë³´ ì¤‘ ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì¶”ì¶œí•  ìˆ˜ ìˆëŠ” ê²ƒì„ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
    - destination: ëª©ì ì§€ (ì˜ˆ: "ë¶€ì‚°", "ì œì£¼ë„")
    - departure: ì¶œë°œì§€ (ì˜ˆ: "ì„œìš¸", "ì¸ì²œ")
    - departure_time: ì¶œë°œ ì‹œê°„ (ì˜ˆ: "ì•„ì¹¨ 9ì‹œ", "ì˜¤í›„ 2ì‹œ")
    - dates: ì—¬í–‰ ë‚ ì§œ/ê¸°ê°„ (ì˜ˆ: "ì´ë²ˆ ì£¼ë§", "12ì›” 15ì¼-17ì¼")
    - budget: ì˜ˆì‚° (ì˜ˆ: "50ë§Œì›", "100ë§Œì›")
    
    ì¶”ì¶œí•  ìˆ˜ ì—†ëŠ” ì •ë³´ëŠ” nullë¡œ ë°˜í™˜í•˜ì„¸ìš”.
    JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”:
    """
    
    response = llm.invoke(prompt)
    try:
        import json
        extracted = json.loads(response.content)
        # ê¸°ì¡´ ì •ë³´ì™€ ë³‘í•©
        for key, value in extracted.items():
            if value and value != "null":
                current_info[key] = value
    except:
        pass
    
    return current_info


# ============================================================================
# Phase 2: ì˜ë„ íŒŒì•… ë° ì—ì´ì „íŠ¸ ë¼ìš°íŒ…
# ============================================================================

def classify_intent_with_llm(user_input: str) -> str:
    """LLMì´ ì‚¬ìš©ì ì˜ë„ íŒŒì•…"""
    llm = get_llm()
    
    prompt = f"""
    ì‚¬ìš©ì ì…ë ¥: "{user_input}"
    
    ì˜ë„ë¥¼ íŒŒì•…í•˜ì„¸ìš”:
    - restaurant: ë§›ì§‘, ìŒì‹ì  ê´€ë ¨
    - dessert: ë””ì €íŠ¸, ì¹´í˜ ê´€ë ¨
    - accommodation: ìˆ™ì†Œ, í˜¸í…” ê´€ë ¨
    - landmark: ê´€ê´‘ì§€, ëª…ì†Œ ê´€ë ¨
    - region: ì§€ì—­ ì¶”ì²œ ê´€ë ¨
    - select: ì‚¬ìš©ìê°€ í•­ëª©ì„ ì„ íƒí•¨ (ì˜ˆ: "ì²« ë²ˆì§¸", "2ë²ˆ", "ì´ê±° ì¢‹ì•„")
    - itinerary: ì¼ì • ìƒì„± ìš”ì²­
    - chat: ì¼ë°˜ ëŒ€í™”
    
    ì˜ë„ë§Œ ë‹µí•˜ì„¸ìš” (í•œ ë‹¨ì–´):
    """
    
    response = llm.invoke(prompt)
    return response.content.strip().lower()


# ============================================================================
# Supervisor Node
# ============================================================================

def supervisor_node(state: TravelPlannerState) -> TravelPlannerState:
    """
    Supervisor: ëŒ€í™” ê´€ë¦¬ + ì˜ë„ íŒŒì•… + ë¼ìš°íŒ…
    
    1. Phase í™•ì¸
    2. í•„ìˆ˜ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ ì—¬ë¶€ ì²´í¬
    3. ì‚¬ìš©ì ì˜ë„ íŒŒì•…
    4. ì ì ˆí•œ ì—ì´ì „íŠ¸ë¡œ ë¼ìš°íŒ… ë˜ëŠ” ì§ì ‘ ì‘ë‹µ
    """
    llm = get_llm()
    user_input = state["user_input"]
    
    # Phase 1: í•„ìˆ˜ ì •ë³´ ìˆ˜ì§‘
    if not state.get("required_info_complete", False):
        # ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì •ë³´ ì¶”ì¶œ
        state["required_info"] = extract_required_info(
            user_input, 
            state.get("required_info", {})
        )
        
        # ëˆ„ë½ëœ ì •ë³´ í™•ì¸
        missing = check_missing_required_info(state["required_info"])
        
        if missing:
            # ëª©ì ì§€ ì§ˆë¬¸ ì‹œ Region Agent í˜¸ì¶œ
            if "destination" in missing or "ëª©ì ì§€" in missing:
                prompt = f"""
                ì‚¬ìš©ìì—ê²Œ ì–´ë””ë¡œ ì—¬í–‰ ê°€ê³  ì‹¶ì€ì§€ ë¬¼ì–´ë³´ì„¸ìš”.
                
                ê·œì¹™:
                - ì§§ê³  ê°„ê²°í•˜ê²Œ
                - ì˜ˆì‹œ í¬í•¨: "ì˜ˆ: ë¶€ì‚°, ì œì£¼ë„, ê°•ë¦‰ ë“±"
                - ê³ ì–‘ì´ ë§íˆ¬: ë¬¸ì¥ ëì—ë§Œ "ëƒ¥" ë¶™ì´ê¸°
                - ì˜ˆì‹œ: "ì–´ë””ë¡œ ê°€ê³  ì‹¶ë‹¤ëƒ¥? (ì˜ˆ: ë¶€ì‚°, ì œì£¼ë„, ê°•ë¦‰ ë“±)"
                """
                response = llm.invoke(prompt)
                state["final_response"] = response.content
                state["next_agent"] = "region"  # Region Agent í˜¸ì¶œ
                return state
            
            # ë¶€ì¡±í•œ ì •ë³´ ì§ˆë¬¸
            prompt = f"""
            ì‚¬ìš©ìì—ê²Œ {missing} ì •ë³´ë¥¼ ë¬¼ì–´ë³´ì„¸ìš”.
            
            ê·œì¹™:
            - ë§¤ìš° ì§§ê³  ê°„ê²°í•˜ê²Œ (í•œ ë¬¸ì¥)
            - ê³ ì–‘ì´ ë§íˆ¬: ë¬¸ì¥ ëì—ë§Œ "ëƒ¥" ë¶™ì´ê¸°
            - ì˜ˆì‹œ: "ì–¸ì œ ì¶œë°œí•œë‹¤ëƒ¥?", "ì˜ˆì‚°ì€ ì–¼ë§ˆëƒ¥?"
            """
            response = llm.invoke(prompt)
            state["final_response"] = response.content
            state["next_agent"] = "chat"  # ì§ì ‘ ì‘ë‹µ
            return state
        else:
            # í•„ìˆ˜ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ
            state["required_info_complete"] = True
            state["current_phase"] = "preference_gathering"
            
            # í™˜ì˜ ë©”ì‹œì§€
            dest = state["required_info"]["destination"]
            prompt = f"""
            ì‚¬ìš©ìê°€ {dest} ì—¬í–‰ì„ ê³„íší•˜ê³  ìˆìŠµë‹ˆë‹¤.
            í•„ìˆ˜ ì •ë³´ë¥¼ ëª¨ë‘ ë°›ì•˜ìœ¼ë‹ˆ, ì´ì œ ë§›ì§‘, ì¹´í˜, ìˆ™ì†Œ, ê´€ê´‘ì§€ ë“±ì„ ì¶”ì²œí•´ì¤„ ìˆ˜ ìˆë‹¤ê³  ì•Œë ¤ì£¼ì„¸ìš”.
            ê·€ì—¬ìš´ ê³ ì–‘ì´ ë§íˆ¬ë¡œ (~ëƒ¥) ì¹œê·¼í•˜ê²Œ ë§í•˜ì„¸ìš”.
            """
            response = llm.invoke(prompt)
            state["final_response"] = response.content
            state["next_agent"] = "chat"
            return state
    
    # Phase 2: ì„ í˜¸ë„ ìˆ˜ì§‘ - ì˜ë„ íŒŒì•…
    intent = classify_intent_with_llm(user_input)
    state["next_agent"] = intent
    
    return state


# ============================================================================
# ì—ì´ì „íŠ¸ ë…¸ë“œë“¤
# ============================================================================

def restaurant_agent_node(state: TravelPlannerState) -> TravelPlannerState:
    """Restaurant ReAct Agent í˜¸ì¶œ"""
    try:
        from Langgraph.restaurant_langgraph import restaurant_graph
        
        result = restaurant_graph.invoke({
            "messages": [("user", state["user_input"])]
        })
        
        state["agent_results"]["restaurant"] = result
        state["final_response"] = result["messages"][-1].content
    except Exception as e:
        state["final_response"] = f"ë§›ì§‘ ì •ë³´ë¥¼ ì°¾ëŠ” ì¤‘ ë¬¸ì œê°€ ìƒê²¼ì–´ëƒ¥... ğŸ˜¿ ({str(e)})"
    
    return state


def landmark_agent_node(state: TravelPlannerState) -> TravelPlannerState:
    """Landmark Agent í˜¸ì¶œ"""
    try:
        from Langgraph.landmark_langgraph import LandmarkWorkflow
        
        workflow = LandmarkWorkflow()
        response = workflow.run(state["user_input"])
        
        state["agent_results"]["landmark"] = {"response": response}
        state["final_response"] = response
    except Exception as e:
        state["final_response"] = f"ê´€ê´‘ì§€ ì •ë³´ë¥¼ ì°¾ëŠ” ì¤‘ ë¬¸ì œê°€ ìƒê²¼ì–´ëƒ¥... ğŸ˜¿ ({str(e)})"
    
    return state


def region_agent_node(state: TravelPlannerState) -> TravelPlannerState:
    """Region Agent í˜¸ì¶œ"""
    try:
        from Langgraph.region_langgraph import region_graph
        
        destination = state.get("required_info", {}).get("destination", "ë¶€ì‚°")
        
        result = region_graph.invoke({
            "user_input": state["user_input"],
            "destination": destination
        })
        
        state["agent_results"]["region"] = result
        state["final_response"] = result.get("final_response", "ì§€ì—­ ì •ë³´ë¥¼ ì°¾ì•˜ì–´ëƒ¥!")
    except Exception as e:
        state["final_response"] = f"ì§€ì—­ ì •ë³´ë¥¼ ì°¾ëŠ” ì¤‘ ë¬¸ì œê°€ ìƒê²¼ì–´ëƒ¥... ğŸ˜¿ ({str(e)})"
    
    return state


def dessert_agent_node(state: TravelPlannerState) -> TravelPlannerState:
    """Dessert/Cafe ReAct Agent í˜¸ì¶œ"""
    try:
        from Langgraph.dessert_langgraph import dessert_graph
        
        result = dessert_graph.invoke({
            "messages": [("user", state["user_input"])]
        })
        
        state["agent_results"]["dessert"] = result
        state["final_response"] = result["messages"][-1].content
    except Exception as e:
        state["final_response"] = f"ë””ì €íŠ¸/ì¹´í˜ ì •ë³´ë¥¼ ì°¾ëŠ” ì¤‘ ë¬¸ì œê°€ ìƒê²´ì–´ëƒ­... ğŸ˜¿ ({str(e)})"
    
    return state


def accommodation_agent_node(state: TravelPlannerState) -> TravelPlannerState:
    """Accommodation ReAct Agent í˜¸ì¶œ"""
    try:
        from Langgraph.accommodation_langgraph import accommodation_graph
        
        result = accommodation_graph.invoke({
            "messages": [("user", state["user_input"])]
        })
        
        state["agent_results"]["accommodation"] = result
        state["final_response"] = result["messages"][-1].content
    except Exception as e:
        state["final_response"] = f"ìˆ™ì†Œ ì •ë³´ë¥¼ ì°¾ëŠ” ì¤‘ ë¬¸ì œê°€ ìƒê²´ì–´ëƒ­... ğŸ˜¿ ({str(e)})"
    
    return state


def chat_agent_node(state: TravelPlannerState) -> TravelPlannerState:
    """ì¼ë°˜ ëŒ€í™” ì²˜ë¦¬"""
    # final_responseê°€ ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    if not state.get("final_response"):
        llm = get_llm()
        prompt = f"ì‚¬ìš©ì ì§ˆë¬¸: {state['user_input']}\n\nì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."
        response = llm.invoke(prompt)
        state["final_response"] = response.content
    
    return state


# ============================================================================
# ê³ ì–‘ì´ ë§íˆ¬ ë³€í™˜ ë…¸ë“œ
# ============================================================================

def cat_speech_node(state: TravelPlannerState) -> TravelPlannerState:
    """ëª¨ë“  ì‘ë‹µì„ ê³ ì–‘ì´ ë§íˆ¬ë¡œ ë³€í™˜"""
    llm = get_llm()
    original = state["final_response"]
    
    # ì´ë¯¸ ê³ ì–‘ì´ ë§íˆ¬ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if "ëƒ¥" in original:
        return state
    
    prompt = f"""
    ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê·€ì—¬ìš´ ê³ ì–‘ì´ ë§íˆ¬ë¡œ ë³€í™˜í•˜ì„¸ìš”.
    
    ê·œì¹™:
    - ë¬¸ì¥ ë: "~ëƒ¥", "~ì´ëƒ¥?", "~í•˜ëƒ¥", "~ë‹¤ëƒ¥" ë“±
    - ìì—°ìŠ¤ëŸ½ê³  ê·€ì—¬ìš´ ëŠë‚Œ
    - ë‚´ìš©ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
    - ë„ˆë¬´ ê³¼í•˜ì§€ ì•Šê²Œ (ëª¨ë“  ë¬¸ì¥ì— ëƒ¥ì„ ë¶™ì´ì§€ ë§ê³  ì ì ˆíˆ)
    
    ì›ë³¸: {original}
    
    ê³ ì–‘ì´ ë§íˆ¬:
    """
    
    response = llm.invoke(prompt)
    state["final_response"] = response.content
    
    return state


# ============================================================================
# ê·¸ë˜í”„ êµ¬ì„±
# ============================================================================

def route_to_agent(state: TravelPlannerState) -> str:
    """ë‹¤ìŒ ë…¸ë“œ ê²°ì •"""
    next_agent = state.get("next_agent", "chat")
    
    # ì§€ì›í•˜ëŠ” ì—ì´ì „íŠ¸ ëª©ë¡
    supported_agents = ["restaurant", "landmark", "region", "dessert", "accommodation", "chat"]
    
    if next_agent in supported_agents:
        return next_agent
    else:
        return "chat"


# ê·¸ë˜í”„ ìƒì„±
workflow = StateGraph(TravelPlannerState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("supervisor", supervisor_node)
workflow.add_node("restaurant", restaurant_agent_node)
workflow.add_node("landmark", landmark_agent_node)
workflow.add_node("region", region_agent_node)
workflow.add_node("dessert", dessert_agent_node)
workflow.add_node("accommodation", accommodation_agent_node)
workflow.add_node("chat", chat_agent_node)
workflow.add_node("cat_speech", cat_speech_node)

# ì‹œì‘ì 
workflow.set_entry_point("supervisor")

# Supervisor â†’ ê° ì—ì´ì „íŠ¸ (ì¡°ê±´ë¶€)
workflow.add_conditional_edges(
    "supervisor",
    route_to_agent,
    {
        "restaurant": "restaurant",
        "landmark": "landmark",
        "region": "region",
        "dessert": "dessert",
        "accommodation": "accommodation",
        "chat": "chat"
    }
)

# ê° ì—ì´ì „íŠ¸ â†’ ê³ ì–‘ì´ ë§íˆ¬ ë³€í™˜
workflow.add_edge("restaurant", "cat_speech")
workflow.add_edge("landmark", "cat_speech")
workflow.add_edge("region", "cat_speech")
workflow.add_edge("dessert", "cat_speech")
workflow.add_edge("accommodation", "cat_speech")
workflow.add_edge("chat", "cat_speech")

# ê³ ì–‘ì´ ë§íˆ¬ â†’ END
workflow.add_edge("cat_speech", END)

# ì»´íŒŒì¼
travel_planner_graph = workflow.compile()


# ============================================================================
# í…ŒìŠ¤íŠ¸
# ============================================================================

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ± Travel Planner Graph í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # ì´ˆê¸° ìƒíƒœ
    initial_state = {
        "messages": [],
        "user_input": "ì—¬í–‰ ê°€ê³  ì‹¶ì–´",
        "current_phase": "required_info",
        "required_info": {},
        "required_info_complete": False,
        "preferences": {},
        "selected_items": {},
        "agent_results": {},
        "itinerary": None,
        "next_agent": None,
        "final_response": ""
    }
    
    result = travel_planner_graph.invoke(initial_state)
    print(f"\nì‘ë‹µ: {result['final_response']}")
    print("\nì™„ë£Œ!")
